# RL-study-2019

8장 까지는 MDP를 알 때 dynamic programming을 통해 문제를 푸는 방법도 배웠고, Model - free로 문제를 푸는 방법에 대해서도 배웠었다.

그래서 Prediction문제와 Control 문제를 푸는 법에 대해서 다루어 보았다.

또한 6강에서 Function approximation을 통해 문제를 scale-up하기도 해봤다ㅎㅎ

8장은 모델을 만들고, 모델을 기반으로 강화학습을 하는 문제! model을 알 때 푸는 것은 planning이고 model을 모를 때 푸는 것은 learning이라는 것을 기억하시고~~

이번 장에서는 planning과 learning을 섞는 법에 대해서도 조금 다룰 것입니다.

### Integrating Learning and Planning

바로 지난 강의에서는 경험으로부터 policy를 직접 학습했다.
그 이전의 강의에서는 value function을 경험으로 부터 직접 학습 했다.
이! 번! 엔! 경험들로 부터 model을 직접적으로 학습하는 것에 대해서 다룬다.

그 후에 모델을 통해서 value function과 policy를 constructing한다.
또한, learning과 planning을 single architecture에 integrate하는 것을 배운다.










ㅇ
