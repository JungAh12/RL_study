# RL-study-2019

Policy Gradient

### Policy- Based Reinforcement Learning

  In the last lecture we approximated the value or action-value function using parameters theta,
    V𝜃(s)   ≈ V^𝜋(s)
    Q𝜃(s,a) ≈ Q^𝜋(s,a)

  A policy was generated directly from the value function
    e.g. using e-greedy

  In this lecture we will directly parametrise the policy
    𝜋𝜃(s,a) = P[a|s,𝜃]

  We will focus again on model-free reinforcement learning

#### Value-Based and Policy-Based RL
















d
